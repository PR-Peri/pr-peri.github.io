---
layout: post
title: "Understanding the Maths Behind Linear Regression Model"
subtitle: "Benefits of using Machine Learning Solutions for Credit Card Fraudulent Detection and Analysis."
date: 2023-06-22 10:45:13 -0400
background: '/img/posts/LR-01.jpg'
---

<style>
    body {
        background-image: url('https://thumbs.gfycat.com/AfraidFlickeringAntlion-size_restricted.gif');
        background-size: cover;
        height: 100vh;
        padding: 0;
        margin: 0;
    }

    .github-link {
        display: flex;
        align-items: left;
        justify-content: left;
        text-align: left;
        color: #0000FF;
        font-style: italic;
        font-size: medium;
        text-decoration: none;
    }

    .github-link img {
        width: 40px;
        height: 40px;
        margin-right: 5px;
    }

    #myBtn {
        display: none;
        position: fixed;
        bottom: 20px;
        right: 30px;
        z-index: 99;
        font-size: 15px;
        border: none;
        outline: none;
        background-color: rgb(238, 208, 37);
        color: white;
        cursor: pointer;
        padding: 10px;
        border-radius: 4px;
    }

    #myBtn:hover {
        background-color: #555;
    }
</style>
<button onclick="topFunction()" id="myBtn" title="Back to top">
    <img class="img-fluid" src="/img/posts/arrow.jpg" height="30" width="30">
</button>

<script>
    document.addEventListener('contextmenu', (e) => {
        e.preventDefault();
    }
    );
    document.onkeydown = function (e) {
        if (event.keyCode == 123) {
            return false;
        }
        if (e.ctrlKey && e.shiftKey && e.keyCode == 'I'.charCodeAt(0)) {
            return false;
        }
        if (e.ctrlKey && e.shiftKey && e.keyCode == 'C'.charCodeAt(0)) {
            return false;
        }
        if (e.ctrlKey && e.shiftKey && e.keyCode == 'J'.charCodeAt(0)) {
            return false;
        }
        if (e.ctrlKey && e.keyCode == 'U'.charCodeAt(0)) {
            return false;
        }
    }

    var mybutton = document.getElementById("myBtn");
    var message = "Right- Click Function Disabled!";


    // When the user scrolls down 20px from the top of the document, show the button
    window.onscroll = function () { scrollFunction() };

    function scrollFunction() {
        if (document.body.scrollTop > 20 || document.documentElement.scrollTop > 20) {
            mybutton.style.display = "block";
        } else {
            mybutton.style.display = "none";
        }
    }

    // When the user clicks on the button, scroll to the top of the document
    function topFunction() {
        document.body.scrollTop = 0;
        document.documentElement.scrollTop = 0;
    }

    function disableselect(e) {
        return false
    }

    function reEnable() {
        return true
    }

    //if IE4+  
    document.onselectstart = new Function("return false")
    document.oncontextmenu = new Function("return false")
    document.oncontextmenu = new Function("alert(message);return false")

    //if NS6  
    if (window.sidebar) {
        document.onmousedown = disableselect
        document.onclick = reEnable

    }

</script>

<html>

<head>
    <title>Understanding Linear Regression: A Step-by-Step Guide</title>
</head>

<body>
    <h1>Understanding Linear Regression: A Step-by-Step Guide</h1>

    <p>
        Linear regression is a fundamental statistical technique used to model the relationship between a dependent
        variable and one or more independent variables. It is widely used in various fields, such as economics, finance,
        and machine learning. In this blog post, we will dive into the world of linear regression, focusing on both
        simple and multiple linear regression models. We will explain how the equations are derived and provide simple
        mathematical examples to illustrate the concepts.
    </p>

    <h3>1. Simple Linear Regression:</h3>

    <h4>1.1. Deriving the Equation:</h4>
    <p>
        To derive the equation for a simple linear regression model, we assume that the relationship between x and y can
        be expressed as:<br>

    <h2><code><strong> y = β₀ + β₁x + ε</strong></code></h2><br>

    Here, y represents the dependent variable, x is the independent variable, β₀ is the y-intercept, β₁ is the
    slope, and ε is the error term. The objective is to estimate the values of β₀ and β₁ that minimize the sum of
    squared errors.
    </p>

    <h4>1.2. Example:</h4>
    <p>
        Let's consider a simple example to illustrate the concept. Suppose we have a dataset of housing prices (y) and
        their corresponding areas (x). We want to find the linear relationship between the area and the price. Here's a
        small dataset:
    </p>

    <table>
        <tr>
            <th>Area (x)</th>
            <th>Price (y)</th>
        </tr>
        <tr>
            <td>1000</td>
            <td>250000</td>
        </tr>
        <tr>
            <td>1500</td>
            <td>350000</td>
        </tr>
        <tr>
            <td>1200</td>
            <td>280000</td>
        </tr>
        <tr>
            <td>1800</td>
            <td>400000</td>
        </tr>
    </table>

    <p>
        Using the least squares method, we can find the best-fitting line. By substituting the given values into the
        equation y = β₀ + β₁x, we can solve for β₀ and β₁. The steps are as follows:
    </p>

    <p>
        Step 1: Calculate the means of x and y:
    </p>
    <p style="color: #0000FF; ">
        <b> x&#772; = (1000 + 1500 + 1200 + 1800) / 4 = 1375<br>
            y&#772; = (250000 + 350000 + 280000 + 400000) / 4 = 320000 </b>
    </p>

    <p>
        Step 2: Calculate the differences from the means:
    </p>
    <p style="color: #0000FF; ">
        <b>
            Δx = [1000 - 1375, 1500 - 1375, 1200 - 1375, 1800 - 1375] = [-375, 125, -175, 425]<br>
            Δy = [250000 - 320000, 350000 - 320000, 280000 - 320000, 400000 - 320000] = [-70000, 30000, -40000,
            80000]</b>
    </p>



    <p>
        Step 3: Calculate the squared differences:</p>

    <p style="color: #0000FF; ">
        <b>
            (Δx)² = [(-375)², 125², (-175)², 425²] = [140625, 15625, 30625, 180625]<br>
            (Δy)² = [(-70000)², 30000², (-40000)², 80000²] = [4900000000, 900000000, 1600000000, 6400000000]</b>
    </p>

    <p>
        Step 4: Calculate the cross-products of Δx and Δy:</p>
    <p style="color: #0000FF; ">
        <b>
            (Δx)(Δy) = [(-375)(-70000), 125(30000), (-175)(-40000), 425(80000)] = [26250000, 3750000, 7000000,
            34000000]</b>
    </p>

    <p>
        Step 5: Calculate the slope (β₁):</p>
    <p style="color: #0000FF; ">
        <b>
            β₁ = Σ((Δx)(Δy)) / Σ(Δx)² = (26250000 + 3750000 + 7000000 + 34000000) / (140625 + 15625 + 30625 + 180625) =
            101500000 / 387500 = 262.58 (approx.)</b>
    </p>

    <p>
        Step 6: Calculate the y-intercept (β₀):</p>
    <p style="color: #0000FF; ">
        <b>
            β₀ = y&#772; - β₁x&#772; = 320000 - 262.58(1375) = -19416.67 (approx.) </b>
    </p>

    <p>
        Thus, the equation for the best-fitting line is:</p>
    <p style="color: #0000FF; ">
        <b>
            y = -19416.67 + 262.58x
        </b>
    </p>


    <h2>Multiple Linear Regression</h2>
    <p>
        Multiple linear regression extends the concept of simple linear regression to include more than one independent
        variable. The equation for multiple linear regression is as follows:
    </p>

    <h2><code><strong> y = β₀ + β₁x₁ + β₂x₂ + ... + βₚxₚ + ε</strong></code></h2><br>

    <p>
        Here, y represents the dependent variable, x₁, x₂, ..., xₚ are the independent variables, β₀ is the y-intercept,
        β₁, β₂, ..., βₚ are the slopes for each independent variable, and ε is the error term.
    </p>
    <p>
        Let's dive into an example to understand the steps involved in multiple linear regression.
    </p>

    <h3>Example:</h3>
    <p>
        Let's expand our previous example of housing prices (y) and their corresponding areas (x) to include an
        additional independent variable, the number of bedrooms (z). The dataset now looks like this:
    </p>

    <table>
        <tr>
            <th>Area (x)</th>
            <th>Bedrooms (z)</th>
            <th>Price (y)</th>
        </tr>
        <tr>
            <td>1000</td>
            <td>2</td>
            <td>250000</td>
        </tr>
        <tr>
            <td>1500</td>
            <td>3</td>
            <td>350000</td>
        </tr>
        <tr>
            <td>1200</td>
            <td>2</td>
            <td>280000</td>
        </tr>
        <tr>
            <td>1800</td>
            <td>4</td>
            <td>400000</td>
        </tr>
    </table>

    <p>Step 1: Calculate the means of x, z, and y:</p>
    <b>
        <p style="color: #0000FF; ">
            x&#772; = (1000 + 1500 + 1200 + 1800) / 4 = 1375
        </p>
        <p style="color: #0000FF; ">
            z&#772; = (2 + 3 + 2 + 4) / 4 = 2.75
        </p>
        <p style="color: #0000FF; ">
            y&#772; = (250000 + 350000 + 280000 + 400000) / 4 = 320000
        </p>
    </b>
    <p>Step 2: Calculate the differences from the means:</p>
    <b>
        <p style="color: #0000FF; ">
            Δx = [1000 - 1375, 1500 - 1375, 1200 - 1375, 1800 - 1375] = [-375, 125, -175, 425]
        </p>
        <p style="color: #0000FF; ">
            Δz = [2 - 2.75, 3 - 2.75, 2 - 2.75, 4 - 2.75] = [-0.75, 0.25, -0.75, 1.25]

        </p>
        <p style="color: #0000FF; ">
            Δy = [250000 - 320000, 350000 - 320000, 280000 - 320000, 400000 - 320000] = [-70000, 30000, -40000, 80000]
        </p>
    </b>

    <p>Step 3: Calculate the squared differences:</p>
    <b>
        <p style="color: #0000FF; ">
            (Δx)² = [(-375)², 125², (-175)², 425²] = [140625, 15625, 30625, 180625]
        </p>
        <p style="color: #0000FF; ">
            (Δz)² = [(-0.75)², 0.25², (-0.75)², 1.25²] = [0.5625, 0.0625, 0.5625, 1.5625]
        </p>
        <p style="color: #0000FF; ">
            (Δy)² = [(-70000)², 30000², (-40000)², 80000²] = [49000000000, 900000000, 1600000000, 6400000000]
        </p>
    </b>

    <p>Step 4: Calculate the cross-products of Δx, Δz, and Δy:</p>
    <b>
        <p style="color: #0000FF; ">
            (Δx)(Δy) = [(-375)(-70000), 125(30000), (-175)(-40000), 425(80000)] = [26250000, 3750000, 7000000, 34000000]
        </p>
        <p style="color: #0000FF; ">
            (Δx)(Δz) = [(-375)(-0.75), 125(0.25), (-175)(-0.75), 425(1.25)] = [281.25, -31.25, 131.25, 531.25]
        </p>
        <p style="color: #0000FF; ">
            (Δz)(Δy) = [(-0.75)(-70000), 0.25(30000), (-0.75)(-40000), 1.25(80000)] = [52500, 7500, 30000, 100000]
        </p>
    </b>

    <p>Step 5: Calculate the coefficients (β₀, β₁, β₂):</p>
    <b>
        <p style="color: #0000FF; ">
            β₁ = [Σ((Δx)(Δy)) - Σ((Δx)(Δz))(Σ(Δz)(Δy))] / [Σ(Δx)² - Σ((Δx)(Δz))²]
        </p>
        <p style="color: #0000FF; "> = (26250000 + 3750000 + 7000000 + 34000000 - (281.25 + -31.25 + 131.25 +
            531.25)(52500
            + 7500 + 30000 + 100000))
            / (140625 + 15625 + 30625 + 180625 - (281.25 + -31.25 + 131.25 + 531.25)²)</p>
        <p style="color: #0000FF; "> = 2782.05 (approx.)</p>

        <p style="color: #0000FF; ">
            β₂ = [Σ((Δz)(Δy)) - Σ((Δx)(Δz))(Σ(Δx)(Δy))] / [Σ(Δz)² - Σ((Δx)(Δz))²]</p>
        <p style="color: #0000FF; "> = (52500 + 7500 + 30000 + 100000 - (281.25 + -31.25 + 131.25 + 531.25)(26250000 +
            3750000 + 7000000 + 34000000))
            / (0.5625 + 0.0625 + 0.5625 + 1.5625 - (281.25 + -31.25 + 131.25 + 531.25)²)</p>
        <p style="color: #0000FF; ">

            = 50782.05 (approx.)</p>

        <p style="color: #0000FF; ">β₀ = y&#772; - β₁x&#772; - β₂z&#772; = 320000 - 2782.05(1375) - 50782.05(2.75) =
            -72067.18 (approx.)</p>

    </b>

    <p>Thus, the equation for the best-fitting plane is:</p>
    <b>
        <p style="color: #0000FF; ">y = -72067.18 + 2782.05x + 50782.05z</p>
    </b>

    <p>In multiple linear regression, the coefficients (β₀, β₁, β₂) represent the intercept and slopes for each
        independent variable, respectively. They determine the relationship between the variables and help predict the
        dependent variable (price in this case) based on the given independent variables (area and number of bedrooms).
    </p>

    <p>By understanding the concepts and following the step-by-step process, you can apply multiple linear regression to
        analyze and model relationships between multiple variables in various real-world scenarios.</p>

    <p>In conclusion, linear regression is a powerful statistical technique that allows us to understand and predict
        relationships between variables. Simple linear regression is suitable when there is only one independent
        variable, while multiple linear regression extends the analysis to multiple independent variables. Both methods
        are widely used in research, data analysis, and machine learning to gain insights and make predictions.</p>


    <p style="text-align: justify;" class="github-link">
        <a href="https://github.com/PR-Peri/Understanding-Maths-Behind-Algorithm/blob/main/"
            title="Link to GitHub Repository" style="color: #0000FF;">
            <img src="https://git-scm.com/images/logos/downloads/Git-Icon-Black.png" alt="Link to GitHub Repository">
            GitHub Repository
        </a>
    </p>

</body>

</html>